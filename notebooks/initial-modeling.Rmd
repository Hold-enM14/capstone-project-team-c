---
title: "initialmodeling"
date: "2025-11-23"
output: html_document
---
Load libraries
```{r}
library(here)
library(dplyr)
library(knitr)
library(tidyr)
library(ggplot2)
library(corrplot)
library(VIM)
```

Importing the data
```{r}
final_data <- read.csv(here("data", "merged_marathon_data.csv"))
```

```{r}
# view merged data
str(final_data)
summary(final_data)
```
Looking at the full dataset for missing values 
```{r}
# missing values for visibility, co, pm10, pm2.5
missing_summary <- final_data %>%
  summarise(across(everything(), ~sum(is.na(.))))

knitr::kable(missing_summary, caption = "Missing Values per Variable")
```

# Spliting the data so Berlin is used as a second case study to show how the method performs with missing data (whether successful or not).

```{r}
main_data <- final_data %>% filter(marathon != "Berlin")
berlin_data <- final_data %>% filter(marathon == "Berlin")
```

```{r}
str(main_data)
```
# Handling Missing Values
```{r}
# missing values
missing_summary <- main_data %>%
  summarise(across(everything(), ~sum(is.na(.))))

knitr::kable(missing_summary, caption = "Missing Values per Variable")
```

Since PM10 has alot of missing values still, we will drop that column completely 
```{r}
main_data <- main_data %>%
  select(-pm10) 
```

Since PM2.5 is often the main pollutant, we decided to use KNN imputation to fill missing PM2.5 values because it predicts missing data using similar rows without assuming a specific parametric relationship, preserves variance, and works well for our relatively small dataset while using correlations with other environmental variables
```{r}
# Impute missing PM2.5 values using 5 nearest neighbors
main_data <- kNN(main_data, variable = "pm25", k = 5) # can change later to see which K gives best model performance 

# remove pm25_imp
cols_to_remove <- c(
  "pm25_imp"
)

main_data <- main_data[, !(names(main_data) %in% cols_to_remove)]

# Check that missing values are filled
summary(main_data$pm25)
```


Convert categorical variables to factors
```{r}
main_data  <- main_data  %>%
  mutate(subgroup = factor(subgroup),
         gender = factor(gender),
         marathon = factor(marathon),
         main_pollutant = factor(main_pollutant))

str(main_data )
```
# Feature engineering 

```{r}
# create interaction terms and convert supershoe to factor
main_data <- main_data %>%
  mutate(
    supershoe = factor(ifelse(year >= 2018, 1, 0), levels = c(0, 1)),
    temp_dew_interaction       = avg_temp * dew_point,
    temp_aqi_interaction       = avg_temp * aqi, 
    temp_precip_interaction    = avg_temp * precipitation,
    temp_wind_interaction      = avg_temp * wind_speed,
    pm25_temp_interaction      = pm25 * avg_temp,
    dew_wind_interaction       = dew_point * wind_speed,
    pressure_temp_interaction  = sea_level_pressure * avg_temp,
    avg_temp_gender_interaction = avg_temp * as.numeric(gender == "male")
  )

str(main_data)
```

# Need to do a Quick correlation check for numeric variables and see what features inroduce multicollinearity

```{r}
# Find numeric columns after feature engineering, excluding 'year'
numeric_vars <- main_data %>%
  select(where(is.numeric)) %>%
  select(-year) %>% 
  names()

numeric_vars
```

Correlation matrix
```{r}
cor_matrix <- cor(main_data[numeric_vars], use = "pairwise.complete.obs")

# rounding
round(cor_matrix, 2)
```

```{r}
corrplot(
  cor_matrix,
  method = "color",
  col = colorRampPalette(c("blue", "white", "red"))(200),
  tl.cex = 0.6
)
```

Observing categorical variables and their distributions
```{r}
table(main_data$pm25_imp) # think this will error out since pm25_imp is removed above
table(main_data$main_pollutant)
table(main_data$supershoe)
```

Removing correlated variables
```{r}
cols_to_remove <- c(
  "high_temp",
  "low_temp",
  "aqi",
  "temp_dew_interaction",
  "temp_precip_interaction",
  "temp_wind_interaction",
  "pm25_temp_interaction",
  "dew_wind_interaction",
  "pressure_temp_interaction",
  "main_pollutant" 
)

main_data <- main_data[, !(names(main_data) %in% cols_to_remove)]
str(main_data)

```

# Data Scaling (for linear regression model)

```{r}
# Identify numeric predictors to scale (exclude outcome and identifiers)
numeric_vars <- main_data %>%
  select(where(is.numeric)) %>%
  select(-avg_chip_seconds, -year, -n) %>%
  names()

# Create scaled versions of the numeric predictors (scaled variables with "scaled_")
scaled_vars <- paste0("scaled_", numeric_vars)
main_data[scaled_vars] <- scale(main_data[numeric_vars])

str(main_data)

```


```{r}
# summary of scaled variables
summary(main_data[scaled_vars])
```

```{r}
# split data into train and test
set.seed(123)

train_index <- sample(1:nrow(main_data), size = 0.9 * nrow(main_data))

train_data <- main_data[train_index, ]
test_data  <- main_data[-train_index, ]
```

```{r}
# updated environmental predictors
env_vars <- c(
  "avg_temp", "precipitation", "dew_point",
  "wind_speed", "visibility", 
  "sea_level_pressure", "pm25", "no2", "ozone"
)

env_data <- main_data %>%
  select(all_of(env_vars))

pca_env <- prcomp(env_data, center = TRUE, scale. = TRUE)
summary(pca_env)
```

```{r}
library(knitr)

pca_var <- data.frame(
  PC = paste0("PC", 1:length(pca_env$sdev)),
  Eigenvalue = pca_env$sdev^2,
  Proportion_Variance = (pca_env$sdev^2) / sum(pca_env$sdev^2),
  Cumulative_Variance = cumsum((pca_env$sdev^2) / sum(pca_env$sdev^2))
)

kable(
  pca_var,
  digits = 3, # can adjust after
  caption = "Table Y: Variance Explained by Principal Components for Environmental Variables"
)
```

```{r}
library(ggplot2)

ggplot(pca_var, aes(x = as.numeric(gsub("PC", "", PC)), y = Proportion_Variance)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Figure Y: Scree Plot for Environmental PCA",
    x = "Principal Component",
    y = "Proportion of Variance Explained"
  ) +
  theme_minimal()
```

```{r}
pca_scores <- as.data.frame(pca_env$x[, 1:3])
colnames(pca_scores) <- c("PC1_env", "PC2_env", "PC3_env")

main_data_pca <- main_data %>%
  bind_cols(pca_scores)
```

```{r}
main_data_pca <- main_data_pca %>%
  mutate(
    marathon = factor(marathon),
    gender = factor(gender),
    subgroup = factor(subgroup),
    supershoe = factor(supershoe)
  )
```

```{r}
set.seed(123)

train_index <- sample(1:nrow(main_data_pca), size = 0.9 * nrow(main_data_pca))

train_data <- main_data_pca[train_index, ]
test_data  <- main_data_pca[-train_index, ]
```

```{r}
lm_full <- lm(
  avg_chip_seconds ~ marathon + gender + subgroup +
    supershoe +
    avg_temp + precipitation + dew_point +
    wind_speed + visibility + sea_level_pressure +
    pm25 + no2 + ozone +
    temp_aqi_interaction + avg_temp_gender_interaction,
  data = train_data
)

summary(lm_full)


#lm_full <- lm(
#  avg_chip_seconds ~ marathon + gender + subgroup2 +
#    supershoe_era + covid_era +
#    high_temp + low_temp + avg_temp +
#    precipitation + dew_point + wind_speed +
#    sea_level_pressure + pm25 + no2 + ozone +
#    temp_dew_interaction + temp_aqi_interaction + 
#    temp_precip_interaction + temp_wind_interaction + pm25_temp_interaction + dew_wind_interaction #+     pressure_temp_interaction + avg_temp_gender_interaction,
#  data = train_data
#)

#summary(lm_full)
```

```{r}
# Predictions
lm_full_pred <- predict(lm_full, newdata = test_data)

# versus Actual
y_test <- test_data$avg_chip_seconds

# RMSE
lm_full_rmse <- sqrt(mean((lm_full_pred - y_test)^2))

# R squared on test set (correlation)
lm_full_r2 <- cor(lm_full_pred, y_test)^2

lm_full_rmse
lm_full_r2
```

```{r}
lm_pca <- lm(
  avg_chip_seconds ~ marathon + gender + subgroup +
    supershoe + PC1_env + PC2_env + PC3_env,
  data = train_data
)

summary(lm_pca)
```

```{r}
lm_pca_pred <- predict(lm_pca, newdata = test_data)

lm_pca_rmse <- sqrt(mean((lm_pca_pred - y_test)^2))
lm_pca_r2   <- cor(lm_pca_pred, y_test)^2

lm_pca_rmse
lm_pca_r2
```

```{r}
model_compare <- data.frame(
  Model = c("Full Linear Model", "PCA Linear Model"),
  RMSE  = c(lm_full_rmse, lm_pca_rmse),
  R2    = c(lm_full_r2,   lm_pca_r2)
)

kable(model_compare, digits = 3,
      caption = "Table Z: Model Performance Comparison on Test Set")
```


```{r}
# create a random forest
library(randomForest)

set.seed(123)

rf_model <- randomForest(
  avg_chip_seconds ~ marathon + gender + subgroup +
    supershoe +
    avg_temp + precipitation + dew_point + 
    wind_speed + visibility + sea_level_pressure +
    pm25 + no2 + ozone +
    temp_aqi_interaction + avg_temp_gender_interaction,
  data = train_data,
  ntree = 500,
  mtry = 5,
  importance = TRUE
)

rf_model
```

```{r}
rf_pred <- predict(rf_model, newdata = test_data)

rf_rmse <- sqrt(mean((rf_pred - y_test)^2))
rf_r2   <- cor(rf_pred, y_test)^2

rf_rmse
rf_r2
```